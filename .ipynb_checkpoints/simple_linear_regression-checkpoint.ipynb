{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one we assume theta_0 and theta_1 params below predict function returns y_hat\n",
    "def predict(theta_0: float, theta_1: float, x_i: float) -> float:\n",
    "    return theta_1 * x_i + theta_0\n",
    "\n",
    "# since we know the actual y_i output we can compute the error  for each pair\n",
    "def error(theta_0: float, theta_1: float, x_i: float, y_i: float) -> float:\n",
    "    \"\"\"\n",
    "    The error from predicting theta_1 * x_i + theta_0, when actual value is y_i\n",
    "    \"\"\"\n",
    "    return predict(theta_0, theta_1, x_i) - y_i\n",
    "\n",
    "# we woudl like to know the total error over the entire dataset\n",
    "# sum of squared errors covers both negative and positive errors, preventing error cancel out. \n",
    "\n",
    "from linear_algebra import Vector\n",
    "\n",
    "def sum_of_sqerrors(theta_0: float, theta_1: float, x: Vector, y: Vector) -> float:\n",
    "    return sum(error(theta_0, theta_1, x_i, y_i) ** 2\n",
    "               for x_i, y_i in zip(x, y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from statistics import correlation, standard_deviation, mean\n",
    "\n",
    "# based on the OLS, the error-minimizing theta_0 and theta_1 \n",
    "def least_squares_fit (x: Vector, y: Vector) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Given two vectors x and y, find the least-squares values of theta_0 and theta_1\n",
    "    \"\"\"\n",
    "    theta_1 = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n",
    "    theta_0 = mean(y) - theta_1 * mean(x)\n",
    "    return theta_0, theta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some good intuition notes by the book:\n",
    "\n",
    "The choice of theta_0 simply states we are trying to predict the averga of the reponse variable via the average the input variable\n",
    "The choice of theta_1 means when the input value increases by standard_deviation(x) the prediction then increases by correlation(x, y) * standard_deviation(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(-100, 110, 10)]\n",
    "y = [3 * i - 5 for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert least_squares_fit(x, y) == (-5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import num_friends_good, daily_minutes_good\n",
    "\n",
    "theta_0, theta_1 = least_squares_fit(num_friends_good, daily_minutes_good)\n",
    "assert 22.9 < theta_0 < 23.0\n",
    "assert 0.9 < theta_1 < 0.905"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common measure of model perfroamnce with OLS is the R-squared, which measures the fraction of the total variation of the output variable that is captured by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import de_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sum_squares(y: Vector) -> float:\n",
    "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
    "    return sum(v **2 for v in de_mean(y))\n",
    "\n",
    "def r_squared(theta_0: float, theta_1: float, x: Vector, y: Vector) -> float:\n",
    "    \"\"\"\n",
    "    the fraction of variation in y captured by the model which equals\n",
    "    1 - the fraction of variation in y not captured by the model\n",
    "    \"\"\"\n",
    "    return 1.0 - (sum_of_sqerrors(theta_0, theta_1, x, y) /\n",
    "                  total_sum_squares(y))\n",
    "\n",
    "rsq = r_squared(theta_0, theta_1, num_friends_good, daily_minutes_good)\n",
    "assert 0.328 < rsq < 0.330"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from gradient_descent import gradient_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "random.seed(0)\n",
    "\n",
    "theta_guess = [random.random(), random.random()] # choose random value to start\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    theta_0, theta_1 = theta_guess\n",
    "    # Partial derivatives wirh respect to theta_0 and theta_1\n",
    "    grad_theta_0 = sum(2 * error(theta_0, theta_1, x_i, y_i) \n",
    "                      for x_i, y_i in zip(num_friends_good, daily_minutes_good))\n",
    "    \n",
    "    \n",
    "    grad_theta_1 = sum(2 * error(theta_0, theta_1, x_i, y_i) * x_i\n",
    "                      for x_i, y_i in zip(num_friends_good, daily_minutes_good))\n",
    "    \n",
    "    # compute loss \n",
    "    loss = sum_of_sqerrors(theta_0, theta_1, num_friends_good, daily_minutes_good)\n",
    "    print(f\"loss: {loss:.3f}\")\n",
    "    \n",
    "    # update the guess\n",
    "    theta_guess = gradient_step(theta_guess, [grad_theta_0, grad_theta_1], -learning_rate) \n",
    "\n",
    "theta_guess = theta_0, theta_1\n",
    "\n",
    "assert 22.9 < theta_0 < 23.0\n",
    "assert 0.9 < theta_1 < 0.905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
