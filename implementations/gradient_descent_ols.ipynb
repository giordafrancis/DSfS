{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the book master learning algortihms I'm attempting to implement from scracth with python machine learning algorithms. I'm focusing here on the pseudocode of running the algorithm in some of the pitfall and assumptions the algorithms might have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data m is 2 and b is 1\n",
    "data_test = [(x, 2 * x + 1) for x in range(10)]\n",
    "xs = [x for x, _ in data_test]\n",
    "ys = [y for _, y in data_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will attempt to find the regression coeficients via the OLS method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = sum((xi - mean(x)) * (yi - mean(y))) / sum(xi - mean(x)) ** 2\n",
    "\n",
    "b = mean(y) - m * mean(x)\n",
    "\n",
    "our hypothesis function is \n",
    "\n",
    "y = b + m*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import math\n",
    "\n",
    "Vector = List[float]\n",
    "\n",
    "def mean (inputs: Vector) -> float:\n",
    "    \"\"\"computes the mean of the vector\"\"\"\n",
    "    assert inputs, \"cannot compute the mean of an empty vector\"\n",
    "    return sum(inputs)/ len(inputs)\n",
    "\n",
    "def de_mean(inputs: Vector) -> float:\n",
    "    \"\"\"\n",
    "    substracts the mean of inputs to each element\n",
    "    \"\"\"\n",
    "    mean_inputs = mean(inputs)\n",
    "    return [input - mean_inputs for input in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert -0.001 <mean(de_mean(xs)) < 0.001 # mean should be close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _slope(xs: Vector, ys: Vector) -> float:\n",
    "    \"\"\"computes the slope for OLS simple regression\"\"\"\n",
    "    return sum(xi * yi \n",
    "               for xi, yi in zip(de_mean(xs), de_mean(ys))) / sum(xi ** 2 for xi in de_mean(xs))\n",
    "\n",
    "def _intercept(xs: Vector, ys: Vector) -> float:\n",
    "    \"\"\" computes the intercept term for OLS simple regression\"\"\"\n",
    "    m = _slope(xs, ys)\n",
    "    return mean(ys) - m * mean(xs)\n",
    "\n",
    "def ols (xs: Vector, ys: Vector) -> Tuple:\n",
    "    \"\"\" computes and returns the intercept and slope for OLS simple regression\"\"\"\n",
    "    return _intercept(xs, ys), _slope(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 2.0)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, m = ols(xs, ys)\n",
    "b, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0.99 < b < 1.01\n",
    "assert 1.99 < m < 2.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some noise to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 3), (2, 5), (3, 7), (4, 9)]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = [(x, 2 * x + 1 ) for x in range(100)]\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 2.0)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = [x for x, _ in data]\n",
    "ys = [y for _, y in data]\n",
    "b, m = ols(xs, ys)\n",
    "\n",
    "b, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat-  the predict values\n",
    "def predict(xs:Vector, ys: Vector, b: float, m: float ) -> float:\n",
    "    return [xi * m + b for xi in xs ]\n",
    "\n",
    "assert len (predict(xs, ys, b, m)) == len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating the error\n",
    "# here we used the root mean squared error\n",
    "\n",
    "def subtract(v1: Vector, v2: Vector) -> float:\n",
    "    assert len(v1) == len(v2)\n",
    "    return [v1_i - v2_i for v1_i, v2_i in zip(v1, v2)]\n",
    "\n",
    "def root_mean_squared_error(ys: Vector, y_hat: Vector) -> float:\n",
    "    assert len(ys) == len(y_hat)\n",
    "    n = len(ys)\n",
    "    return  math.sqrt(sum(error ** 2 for error in subtract(y_hat, ys)) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = predict(xs, ys, b, m) # predict values y_hat\n",
    "root_mean_squared_error(ys, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I've ttempted to implement stochastic gradient descent for the same set of data. Stochastic gradient descent is not used to calculate the coeficients for linear regression in\n",
    "practice unless the dataset prevents traditional Ordinary Least Squares being used (e.g. a\n",
    "very large dataset). Nevertheless, linear regression does provide a useful exercise for practicing\n",
    "stochastic gradient descent which is an important algorithm used for minimizing cost functions\n",
    "by machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each iteration the coefcients, called weights (w) in machine\n",
    "learning language are updated using the equation:\n",
    "\n",
    " w = w  -  alpha * delta \n",
    "\n",
    "where delta is: \n",
    "\n",
    "delta = derivative (costs) \n",
    "\n",
    "\n",
    "Where w is the coefcient or weight being optimized, alpha is a learning rate that you must\n",
    "configure (e.g. 0.1) and gradient is the error for the model on the training data attributed to\n",
    "the weight.\n",
    "\n",
    "Our hypothesis function is:\n",
    "\n",
    "y = w_0 + w_1 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the error per point\n",
    "def predict_point(x: float, w_0: float = 0.0, w_1: float = 0.0) -> float:\n",
    "    return w_0 + w_1 * x \n",
    "\n",
    "def error_point(x: float, y: float, w_0: float = 0.0 , w_1: float = 0.0) -> float:\n",
    "    \"\"\" Calculates the prediction error at point x\"\"\"\n",
    "    return predict_point(x, w_0, w_1) - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert error_point(0, 1) == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the derivatives of the costs for both weights and update \n",
    "\n",
    "alpha = 0.01 # set initial learning rate\n",
    "def _update_w0(x: float, y: float, w_0: float,w_1: float, alpha: float) -> float:\n",
    "    \"\"\"Update w0, we will use just the error as the gradient\"\"\"\n",
    "    return w_0 - alpha * error_point(x, y, w_0, w_1)\n",
    "\n",
    "def _update_w1(x: float, y: float, w_0: float,w_1: float, alpha: float) -> float:\n",
    "    \"\"\"Update w1, the error is filtered by the input x that caused it\"\"\"\n",
    "    return w_1 - alpha * error_point(x, y, w_0, w_1) * x\n",
    "\n",
    "def update_W(x: float, y: float, w_0: float,w_1: float, alpha: float) -> Tuple[float]:\n",
    "    \"\"\" Update w_0 and w_1 in one step\"\"\"\n",
    "    return _update_w0(x, y, w_0, w_1, alpha), _update_w1(x, y, w_0, w_1, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0, w_1 = (0, 0) # test only\n",
    "assert update_W(1, 1, w_0, w_1, 0.01) == (0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_error(data: List[Tuple[int, float]]) -> None:\n",
    "    \"\"\" Plots error vs epoch \"\"\"\n",
    "    \n",
    "    epochs = [epoch for epoch, _ in data]\n",
    "    errors = [error for _, error in data]\n",
    "    \n",
    "    plt.plot(epochs, errors , color='green', marker='o', linestyle='solid')\n",
    "    # add a title\n",
    "    plt.title(\"error vs epoch\")\n",
    "    # add a label to the x and y-axis\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(data: List[Vector], alpha: float,  epochs: int = 20) -> Tuple[float]:\n",
    "    \"\"\"update of vectors weights w_0 and w_1 with stochastic gradient descent\"\"\"\n",
    "    \n",
    "    w_0, w_1 = (0, 0) # initialize W randomly\n",
    "    # in this case random data does not converge with stochastic gradient descent   \n",
    "    data_gen = itertools.cycle(data) \n",
    "    errors = []\n",
    "    for epoch in range(epochs):\n",
    "        x, y = next(data_gen)\n",
    "        w_0, w_1 = update_W(x, y, w_0,w_1, alpha)\n",
    "        errors.append((epoch, error_point(x, y, w_0, w_1)))\n",
    "    plot_error(errors)\n",
    "    return w_0, w_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 2.0)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.19924323545682285, 2.0203437326961264)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 epochs seem the best value\n",
    "stochastic_gradient_descent(data, alpha = 0.001, epochs= 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 3), (2, 5), (3, 7)]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract(v1: Vector, v2: Vector) -> Vector:\n",
    "    \"\"\"Subtracts 2 vectors of equal length\"\"\"\n",
    "    assert len(v1) == len(v2)\n",
    "    return [v1_i - v2_i for v1_i, v2_i in zip(v1, v2)]\n",
    "\n",
    "assert subtract([1, 2], [1, 2]) == [0, 0]\n",
    "\n",
    "def scalar_multiply(s: float, v1: Vector) -> Vector:\n",
    "    return [v1_i * s for v1_i in v1]\n",
    "\n",
    "assert scalar_multiply(0, [1, 2]) == [0, 0]\n",
    "\n",
    "def vector_sum(inputs: List[Vector]) -> float:\n",
    "    \"\"\"sum the ith element of each input vector\"\"\"\n",
    "    l = len(inputs[0])\n",
    "    assert all(len(vector) == l for vector in inputs), \" All vectors lenghts must be the same\"\n",
    "    return [sum(vector[i] for vector in inputs) for i in range(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_1(x: int, y: int, w_0: float, w_1: float) -> float:\n",
    "    \"\"\"Calculates the gradient update for 1 point for theta 1 param\"\"\"\n",
    "    return error_point(x, y, w_0, w_1) *  x\n",
    "\n",
    "def _gradient_0(x: int, y: int, w_0: float, w_1: float) -> float:\n",
    "    \"\"\"Calculates the gradient update for 1 point for theta 1 param\"\"\"\n",
    "    return error_point(x, y, w_0, w_1)\n",
    "\n",
    "def gradient_point(x: int, y: int, w_0: float, w_1: float) -> Vector:\n",
    "    return [_gradient_0(x, y, w_0, w_1), _gradient_1(x, y, w_0, w_1)]\n",
    "\n",
    "def gradient_step(inputs: Tuple, w_0: float, w_1: float, alpha: float) -> Vector:\n",
    "    l = len(inputs)\n",
    "    return scalar_multiply(alpha,\n",
    "                           scalar_multiply(1/l, \n",
    "                           vector_sum([gradient_point(x, y, w_0, w_1) for x, y in inputs]))\n",
    "                          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(data: List[Vector], alpha: float,  epochs: int = 20) -> Tuple[float]:\n",
    "    \"\"\"update of vectors weights w_0 and w_1 with batch gradient descent\"\"\"\n",
    "    \n",
    "    w_0, w_1 = (random.random(), random.random()) # initialize W randomly\n",
    "    for epoch in range(epochs):\n",
    "        gradient = gradient_step(data, w_0, w_1, alpha)\n",
    "        w_0, w_1 = subtract([w_0, w_1], gradient)        \n",
    "    return w_0, w_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-92.73491796969607, -6210.136540110594)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_0, w_1 = batch_gradient_descent(data, 0.001, 10)\n",
    "w_0, w_1\n",
    "# y_hat = predict(xs, ys, w_0, w_1)\n",
    "# root_mean_squared_error(ys, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
