{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a classification algorithm traditionally limited to only two-class classification\n",
    "problems. If you have more than two classes then the Linear Discriminant Analysis is the\n",
    "preferred linear classification technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a simple and powerful linear classi\f",
    "cation algorithm. It also has limitations\n",
    "that suggest at the need for alternate linear classi\f",
    "cation algorithms.\n",
    "\n",
    "- Two-Class Problems. Logistic regression is intended for two-class or binary classi\f",
    "cation\n",
    "problems. It can be extended for multiclass classi\f",
    "cation, but is rarely used for this purpose.\n",
    "- Unstable With Well Separated Classes. Logistic regression can become unstable\n",
    "when the classes are well separated.\n",
    "- Unstable With Few Examples. Logistic regression can become unstable when there\n",
    "are few examples from which to estimate the parameters.\n",
    "\n",
    "Linear discriminant analysis does address each of these points and is the go-to linear method\n",
    "for multiclass classi\f",
    "cation problems. Even with binary-classi\f",
    "cation problems, it is a good idea\n",
    "to try both logistic regression and linear discriminant analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representation of LDA is pretty straight forward. It consists of statistical properties of your\n",
    "data, calculated for each class. \n",
    "\n",
    "For a single input variable (x) this is the mean and the variance\n",
    "of the variable for each class.\n",
    "\n",
    "For multiple variables, this is same properties calculated over the multivariate Gaussian,\n",
    "namely the means and the covariance matrix (this is a multi-dimensional generalization of\n",
    "variance). These statistical properties are estimated from your data and plug into the LDA\n",
    "equation to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA makes some simplifying assumptions about your data\n",
    "- That your data is Gaussian, that each variable is is shaped like a bell curve when plotted.\n",
    "- That each attribute has the same variance, that values of each variable vary around the\n",
    "mean by the same amount on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA makes predictions by estimating the probability that a new set of inputs belongs to each\n",
    "class. The class that gets the highest probability is the output class and a prediction is made.\n",
    "The model uses Bayes Theorem to estimate the probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a general statement, we can state Baye's theorem as follows\\\n",
    "\\begin{equation}\n",
    "\\label{eq:bayes}\n",
    "P(Y=k|\\textbf{X=x}) = P(k) \\frac{P(\\textbf{x}|k)}{P(\\textbf{x})} ~~~~~|| I,\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging the Gaussian\n",
    "into the above equation and simplifying we end up with the equation below. It is no longer a\n",
    "probability as we discard some terms. Instead it is called a discriminate function for class k. It\n",
    "is calculated for each class k and the class that has the largest discriminant value will make the\n",
    "output classi\f",
    "cation (Y = k):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dk(x) = x * mean_k/sigma2 - mean_k^2/(2 * sigma) + ln(P(k))\n",
    "\n",
    "Dk(x) is the discriminate function for class k given input x, the meank, sigma2 and P(k)\n",
    "are all estimated from your data. The ln() function is the natural logarithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Data For LDA\n",
    "This section lists some suggestions you may consider when preparing your data for use with\n",
    "LDA.\n",
    "\n",
    "- Classi\f",
    "cation Problems. This might go without saying, but LDA is intended for\n",
    "classi\f",
    "cation problems where the output variable is categorical. LDA supports both binary\n",
    "and multiclass classi\f",
    "cation.\n",
    "- Gaussian Distribution. The standard implementation of the model assumes a Gaussian\n",
    "distribution of the input variables. Consider reviewing the univariate distributions of each\n",
    "attribute and using transforms to make them more Gaussian-looking (e.g. log and root\n",
    "for exponential distributions and Box-Cox for skewed distributions).\n",
    "- Remove Outliers. Consider removing outliers from your data. These can skew the basic\n",
    "statistics used to separate classes in LDA such the mean and the standard deviation.\n",
    "- Same Variance. LDA assumes that each input variable has the same variance. It almost\n",
    "always a good idea to standardize your data before using LDA so that it has a mean of 0\n",
    "and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to step through how to calculate an LDA model for simple dataset with one input\n",
    "and one output variable. This is the simplest case for LDA. This tutorial will to cover:\n",
    "1. Dataset: Introduce the dataset that we are going to model. We will use the same dataset\n",
    "as the training and the test dataset.\n",
    "2. Learning the Model: How to learn the LDA model from the dataset including all of\n",
    "the statistics needed to make predictions.\n",
    "3. Making Predictions: How to use the learned model to make predictions for each instance\n",
    "in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a contrived simple two-dimensional dataset containing the input variable X and the\n",
    "output class variable Y . All values for X were drawn from a Gaussian distribution and the class\n",
    "variable Y has the value 0 or 1. The instances in the two classes were separated to make the\n",
    "prediction problem simpler. All instances in class 0 were drawn from a Gaussian distribution\n",
    "with a mean of 5 and a standard deviation of 1. All instances in class 1 were drawn from a\n",
    "Gaussian distribution with a mean of 20 and a standard deviation of 1.\n",
    "The classes do not interact and should be separable with a linear model like LDA. It is also\n",
    "handy to know the actual statistical properties of the data because we can generate more test\n",
    "instances later to see how well LDA has learned the model. Below is the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StringIO(\"\"\"X Y\n",
    "4.667797637 0\n",
    "5.509198779 0\n",
    "4.702791608 0\n",
    "5.956706641 0\n",
    "5.738622413 0\n",
    "5.027283325 0\n",
    "4.805434058 0\n",
    "4.425689143 0\n",
    "5.009368635 0\n",
    "5.116718815 0\n",
    "6.370917709 0\n",
    "2.895041947 0\n",
    "4.666842365 0\n",
    "5.602154638 0\n",
    "4.902797978 0\n",
    "5.032652964 0\n",
    "4.083972925 0\n",
    "4.875524106 0\n",
    "4.732801047 0\n",
    "5.385993407 0\n",
    "20.74393514 1\n",
    "21.41752855 1\n",
    "20.57924186 1\n",
    "20.7386947 1\n",
    "19.44605384 1\n",
    "18.36360265 1\n",
    "19.90363232 1\n",
    "19.10870851 1\n",
    "18.18787593 1\n",
    "19.71767611 1\n",
    "19.09629027 1\n",
    "20.52741312 1\n",
    "20.63205608 1\n",
    "19.86218119 1\n",
    "21.34670569 1\n",
    "20.333906 1\n",
    "21.02714855 1\n",
    "18.27536089 1\n",
    "21.77371156 1\n",
    "20.65953546 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cols(cols): return cols.lower().strip() \n",
    "lda = pd.read_csv(dataset, sep=' ').rename(columns = clean_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA model requires the estimation of statistics from the training data:\n",
    "1. Mean of each input value for each class\n",
    "2. Probability of an instance belong to each class.\n",
    "3. Covariance for the input data for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.975415506999999, 20.087062921)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of each input for each class\n",
    "mean_0 = lda.loc[lda.y.eq(0), 'x'].mean()\n",
    "mean_1 = lda.loc[lda.y.eq(1), 'x'].mean()\n",
    "\n",
    "mean_0, mean_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of an instance belongs to each class\n",
    "p_y0 = lda.loc[lda.y.eq(0), 'y'].count()/ lda.shape[0]\n",
    "p_y1 = lda.loc[lda.y.eq(1), 'y'].count()/ lda.shape[0]\n",
    "\n",
    "p_y0, p_y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can understand\n",
    "the variance as the di\u000b",
    "erence of each instance from the mean. The di\u000b",
    "erence is squared so\n",
    "the variance is often written to include these units. It does not mean you need to square the\n",
    "variance value when using it. We can calculate the variance for our dataset in two steps:\n",
    "1. Calculate the squared di\u000b",
    "erence for each input variable from the group mean.\n",
    "2. Calculate the mean of the squared di\u000b",
    "erence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqr_difference(df, class_value: int):\n",
    "    \"\"\"\n",
    "    Calculates the sum of the squared difference for each class\n",
    "    \"\"\"\n",
    "    mean_class = df.loc[df.y.eq(class_value), 'x'].mean()\n",
    "    df_class = df.loc[df.y.eq(class_value)]\n",
    "    return np.sum(\n",
    "        np.square(df_class['x'] - mean_class)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.493167084411787"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqr_difference(lda, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can calculate the variance as the average squared di\u000b",
    "erence from the mean as:\n",
    "\n",
    "variance = (1/count(x) -count(classes)) X sum(SquaredDifference(xi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8329315056876604"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = 1/(lda.shape[0] -lda['y'].nunique()) * sum(sqr_difference(lda, i) for i in range(2))\n",
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions are made by calculating the discriminant\n",
    "function for each class and predicting the class with the largest value. The discriminant function\n",
    "for a class given an input (x) is calculated using:\n",
    "\n",
    "\n",
    "Dk(x) = x * mean_k/sigma2 - mean_k^2/(2 * sigma) + ln(P(k))\n",
    "\n",
    "Where x is the input value, mean, variance and probability are calculated above for the class\n",
    "we are discriminating. After calculating the discriminant value for each class, the class with\n",
    "the largest discriminant value is taken as the prediction. \n",
    "\n",
    "Let's step through the calculation of\n",
    "the discriminate value of each class for the \f",
    "rst instance. The \f",
    "rst instance in the dataset is:\n",
    "**X = 4:667797637 and Y = 0**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.667797637"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.loc[0,'x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminant(x: float, class_value: int, var: float, mean: float, pb: float)-> float:\n",
    "    \"\"\"\n",
    "    Calculates the discriminant function dependent on value\n",
    "    \"\"\"\n",
    "    return x * (mean/ var) - (mean**2/ (2 * var)) + (1/np.e**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = lda.assign(disc_y0 = [discriminant(x, 0, variance, mean_0, p_y0) for x in lda['x']],\n",
    "           disc_y1 = [discriminant(x, 1, variance, mean_1, p_y1) for x in lda['x']],\n",
    "           prediction = lambda df: df.loc[:, ['disc_y0', 'disc_y1']].idxmax(axis='columns').eq('disc_y1').astype(int)\n",
    "                )\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>disc_y0</th>\n",
       "      <th>disc_y1</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18.363603</td>\n",
       "      <td>1</td>\n",
       "      <td>95.439267</td>\n",
       "      <td>201.254234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20.527413</td>\n",
       "      <td>1</td>\n",
       "      <td>108.364527</td>\n",
       "      <td>253.436912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20.738695</td>\n",
       "      <td>1</td>\n",
       "      <td>109.626592</td>\n",
       "      <td>258.532201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.717676</td>\n",
       "      <td>1</td>\n",
       "      <td>103.527661</td>\n",
       "      <td>233.909210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.895042</td>\n",
       "      <td>0</td>\n",
       "      <td>3.039692</td>\n",
       "      <td>-171.787187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.083973</td>\n",
       "      <td>0</td>\n",
       "      <td>10.141627</td>\n",
       "      <td>-143.114804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.702792</td>\n",
       "      <td>0</td>\n",
       "      <td>13.838066</td>\n",
       "      <td>-128.191308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20.333906</td>\n",
       "      <td>1</td>\n",
       "      <td>107.208635</td>\n",
       "      <td>248.770275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.579242</td>\n",
       "      <td>1</td>\n",
       "      <td>108.674119</td>\n",
       "      <td>254.686820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.956707</td>\n",
       "      <td>0</td>\n",
       "      <td>21.328176</td>\n",
       "      <td>-97.951762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x  y     disc_y0     disc_y1  prediction\n",
       "25  18.363603  1   95.439267  201.254234           1\n",
       "31  20.527413  1  108.364527  253.436912           1\n",
       "23  20.738695  1  109.626592  258.532201           1\n",
       "29  19.717676  1  103.527661  233.909210           1\n",
       "11   2.895042  0    3.039692 -171.787187           0\n",
       "16   4.083973  0   10.141627 -143.114804           0\n",
       "2    4.702792  0   13.838066 -128.191308           0\n",
       "35  20.333906  1  107.208635  248.770275           1\n",
       "22  20.579242  1  108.674119  254.686820           1\n",
       "3    5.956707  0   21.328176  -97.951762           0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare the predictions to the dataset, you can see that LDA has achieved an accuracy\n",
    "of 100% (no errors). This is not surprising given that the dataset was contrived so that the\n",
    "groups for Y = 0 and Y = 1 were clearly separable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
